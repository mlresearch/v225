---
title: A Probabilistic Method to Predict Classifier Accuracy on Larger Datasets given
  Small Pilot Data
abstract: Practitioners building classifiers often start with a smaller pilot dataset
  and plan to grow to larger data in the near future. Such projects need a toolkit
  for extrapolating how much classifier accuracy may improve from a 2x, 10x, or 50x
  increase in data size. While existing work has focused on finding a single “best-fit”
  curve using various functional forms like power laws, we argue that modeling and
  assessing the uncertainty of predictions is critical yet has seen less attention.
  In this paper, we propose a Gaussian process model to obtain probabilistic extrapolations
  of accuracy or similar performance metrics as dataset size increases. We evaluate
  our approach in terms of error, likelihood, and coverage across six datasets. Though
  we focus on medical tasks and image modalities, our open source approach generalizes to any kind of classifier.
software: https://github.com/tufts-ml/extrapolating-classifier-accuracy-to-larger-datasets
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: harvey23a
month: 0
tex_title: A Probabilistic Method to Predict Classifier Accuracy on Larger Datasets
  given Small Pilot Data
firstpage: 129
lastpage: 144
page: 129-144
order: 129
cycles: false
bibtex_author: Harvey, Ethan and Chen, Wansu and Kent, David M. and Hughes, Michael
  C.
author:
- given: Ethan
  family: Harvey
- given: Wansu
  family: Chen
- given: David M.
  family: Kent
- given: Michael C.
  family: Hughes
date: 2023-12-04
address: 
container-title: Proceedings of the 3rd Machine Learning for Health Symposium
volume: '225'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 4
pdf: https://proceedings.mlr.press/v225/harvey23a/harvey23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
